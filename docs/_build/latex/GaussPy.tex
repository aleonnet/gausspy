% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,openany,oneside]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}
\usepackage{eqparbox}
\usepackage{amsfonts}
\usepackage{amsfonts}

\addto\captionsenglish{\renewcommand{\figurename}{Fig. }}
\addto\captionsenglish{\renewcommand{\tablename}{Table }}
\SetupFloatingEnvironment{literal-block}{name=Listing }



\title{GaussPy Documentation}
\date{February 28, 2017}
\release{1.0}
\author{R. Lindner, C. Vera-Ciro, C. Murray, E. Bernstein-Cooper}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\setcounter{tocdepth}{1}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ch\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@cpf\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\renewcommand\PYGZsq{\textquotesingle}

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}



\chapter{Introduction}
\label{intro:welcome-to-gausspy-s-documentation}\label{intro:introduction}\label{intro:intro}\label{intro::doc}
When interpreting data, it is useful to fit models made up of parametrized functions.  Gaussian functions, described simply by three parameters and often physically well-motivated, provide a convenient basis set of functions for such a model. However, any set of Gaussian functions is not an orthogonal basis, and therefore any solution implementing them will not be unique. Furthermore, determining fits to spectra involving more than one Gaussian function is complex, and the crucial step of guessing the number of functions and their parameters is not straightforward. Typically, reasonable fits can be determined iteratively and by-eye. However, for large sets of data, analysis by-eye requires an unreasonable amount of processing time and is unfeasible.

This document describes the installation and use of GaussPy, a code for implementing an algorithm called Autonomous Gaussian Decomposition (AGD). AGD using computer vision and machine learning techniques to provide optimized initial guesses for the parameters of a multi-component Gaussian model automatically and efficiently. The speed and adaptability of AGD allow it to interpret large volumes of spectral data efficiently. Although it was initially designed for applications in radio astrophysics, AGD can be used to search for one-dimensional Gaussian (or any other single-peaked spectral profile)-shaped components in any data set.

To determine how many Gaussian functions to include in a model and what their parameters are, AGD uses a technique called derivative spectroscopy. The derivatives of a spectrum can efficiently identify shapes within that spectrum corresponding to the underlying model, including gradients, curvature and edges. The details of this method are described fully in \href{http://iopscience.iop.org/article/10.1088/0004-6256/149/4/138/meta}{Lindner et al. (2015), AJ, 149, 138}.


\chapter{Installation}
\label{install:installation}\label{install::doc}\label{install:install}

\section{Dependencies}
\label{install:dependencies}
You will need the following packages to run GaussPy. We list the version of each
package which we know to be compatible with GaussPy.
\begin{itemize}
\item {} 
\href{http://www.numpy.org/}{python 2.7}

\item {} 
\href{http://www.numpy.org/}{numpy (v1.12.1)}

\item {} 
\href{http://www.scipy.org/}{scipy (v0.17.0)}

\item {} 
\href{https://lmfit.github.io/lmfit-py/intro.html}{lmfit (v0.9.3)}

\item {} 
\href{http://www.h5py.org/}{h5py (v2.0.1)}

\end{itemize}

If you do not already have Python 2.7, you can install the \href{https://store.continuum.io/cshop/anaconda/}{Anaconda Scientific
Python distribution}, which comes
pre-loaded with \emph{numpy}, \emph{scipy}, and \emph{h5py}.


\section{Optional Dependencies}
\label{install:optional-dependencies}
If you wish to use GaussPy's plotting capabilities you will need to install
\emph{matplotlib}:
\begin{itemize}
\item {} 
\href{http://matplotlib.org/}{matplotlib (\textgreater{} v1.1.1)}

\end{itemize}

If you wish to use optimization with Fortran code you will need
\begin{itemize}
\item {} 
\href{http://www.gnu.org/software/gsl/}{GNU Scientific Library (GSL)}

\end{itemize}


\section{Download GaussPy}
\label{install:download-gausspy}
Download GaussPy using git \$ git clone git://github.com/gausspy/gausspy.git


\section{Installing Dependencies on Linux}
\label{install:installing-dependencies-on-linux}
You will need several libraries which the \emph{GSL}, \emph{h5py}, and \emph{scipy} libraries
depend on. Install these required packages with:

\begin{Verbatim}[commandchars=\\\{\}]
sudo apt\PYGZhy{}get install libblas\PYGZhy{}dev liblapack\PYGZhy{}dev gfortran libgsl0\PYGZhy{}dev libhdf5\PYGZhy{}serial\PYGZhy{}dev
sudo apt\PYGZhy{}get install hdf5\PYGZhy{}tools
\end{Verbatim}

Install pip for easy installation of python packages:

\begin{Verbatim}[commandchars=\\\{\}]
sudo apt\PYGZhy{}get install python\PYGZhy{}pip
\end{Verbatim}

Then install the required python packages:

\begin{Verbatim}[commandchars=\\\{\}]
sudo pip install scipy numpy h5py lmfit
\end{Verbatim}

Install the optional dependencies for plotting and optimization:

\begin{Verbatim}[commandchars=\\\{\}]
sudo pip install matplotlib
sudo apt\PYGZhy{}get install libgsl0\PYGZhy{}dev
\end{Verbatim}


\section{Installing Dependencies on OSX}
\label{install:installing-dependencies-on-osx}
Installation on OSX can be done easily with homebrew. Install pip for easy
installation of python packages:

\begin{Verbatim}[commandchars=\\\{\}]
sudo easy\PYGZus{}install pip
\end{Verbatim}

Then install the required python packages:

\begin{Verbatim}[commandchars=\\\{\}]
sudo pip install numpy scipy h5py lmfit
\end{Verbatim}

Install the optional dependencies for plotting and optimization:

\begin{Verbatim}[commandchars=\\\{\}]
sudo pip install matplotlib
sudo brew install gsl
\end{Verbatim}


\section{Installing GaussPy}
\label{install:installing-gausspy}
To install make sure that all dependences are already installed and properly
linked to python --python has to be able to load them--. Then cd to the local
directory containing GaussPy and install via

\begin{Verbatim}[commandchars=\\\{\}]
python setup.py install
\end{Verbatim}

If you don't have root access and/or wish a local installation of
GaussPy then use

\begin{Verbatim}[commandchars=\\\{\}]
python setup.py install \PYGZhy{}\PYGZhy{}user
\end{Verbatim}

change the `requires' statement in setup.py to include \emph{scipy} and \emph{lmfit}.


\chapter{Simple Example Tutorial}
\label{tutorial::doc}\label{tutorial:simple-example-tutorial}\label{tutorial:id1}

\section{Constructing a GaussPy-Friendly Dataset}
\label{tutorial:constructing-a-gausspy-friendly-dataset}
Before implementing AGD, we first must put data into a format readable by
GaussPy. GaussPy requires the indepenent and dependent spectral arrays (e.g.,
channels and amplitude) and an estimate of the per-channel noise in the specrum.

To begin, we can create a simple Gaussian function of the form:
\phantomsection\label{tutorial:equation-spectra}\begin{gather}
\begin{split}S(x_i) = \sum_{k=1}^{\texttt{NCOMPS}} {\texttt{AMP}_k} \exp\left[-\frac{4\ln 2 (x_i
- \texttt{MEAN}_k)^2}{\texttt{FWHM}_k^2} \right] + \texttt{NOISE},
\qquad i = 1, \cdots, \texttt{NCHANNELS}\end{split}\label{tutorial-spectra}
\end{gather}
where,
\begin{enumerate}
\item {} 
\code{NCOMPS} is the number of Gaussian components in each spectrum.

\item {} 
\code{(AMP, MEAN, FWHM)} are the amplitude, mean location, and
full-width-half-maximum of each Gaussian component.

\item {} 
\code{NCHANNELS} is the number of channels in the spectrum (sets the
resolution).

\item {} 
\code{NOISE} is the level of noise introduced in each spectrum, described by the root mean square (RMS) noise per channel.

\end{enumerate}

In the next example we will show how to implement this in python. We have made
the following assumptions:
\begin{enumerate}
\item {} 
\code{NCOMPS = 1} (to begin with a simple, single Gaussian)

\item {} 
\code{AMP = 1.0, MEAN = 256, FWHM = 20} (fixed Gaussian parameters)

\item {} 
\code{NCHANNELS = 512}

\item {} 
\code{RMS = 0.05}

\end{enumerate}

In Fig. \hyperref[tutorial:simple-gaussian]{ \ref*{tutorial:simple-gaussian}} we display the spectrum with the single Gaussian
described above.
\begin{figure}[htbp]
\centering
\capstart

\includegraphics[width=5in]{{simple_gaussian}.png}
\caption{Example spectrum containing a single Gaussian function with added spectral noise.}\label{tutorial:simple-gaussian}\end{figure}

The following code describes an example of how to create a spectrum
with a Gaussian shape and store the channels, amplitude and error arrays in a
python pickle file to be read later by GaussPy.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Create simple Gaussian profile with added noise}
\PYG{c+c1}{\PYGZsh{} Store in format required for GaussPy}

\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}

\PYG{c+c1}{\PYGZsh{} create a function which returns the values of the Gaussian function for a}
\PYG{c+c1}{\PYGZsh{} given x}
\PYG{k}{def} \PYG{n+nf}{gaussian}\PYG{p}{(}\PYG{n}{amp}\PYG{p}{,} \PYG{n}{fwhm}\PYG{p}{,} \PYG{n}{mean}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{n}{amp} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{4.} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)} \PYG{o}{*} \PYG{p}{(}\PYG{n}{x}\PYG{o}{\PYGZhy{}}\PYG{n}{mean}\PYG{p}{)}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2} \PYG{o}{/} \PYG{n}{fwhm}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Data properties}
\PYG{n}{RMS} \PYG{o}{=} \PYG{l+m+mf}{0.05}
\PYG{n}{NCHANNELS} \PYG{o}{=} \PYG{l+m+mi}{512}
\PYG{n}{FILENAME} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{simple\PYGZus{}gaussian.pickle}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Component properties}
\PYG{n}{AMP} \PYG{o}{=} \PYG{l+m+mf}{1.0}
\PYG{n}{FWHM} \PYG{o}{=} \PYG{l+m+mi}{20}
\PYG{n}{MEAN} \PYG{o}{=} \PYG{l+m+mi}{256}

\PYG{c+c1}{\PYGZsh{} Initialize}
\PYG{n}{data} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{chan} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{n}{NCHANNELS}\PYG{p}{)}
\PYG{n}{errors} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{n}{NCHANNELS}\PYG{p}{)} \PYG{o}{*} \PYG{n}{RMS}

\PYG{n}{spectrum} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{randn}\PYG{p}{(}\PYG{n}{NCHANNELS}\PYG{p}{)} \PYG{o}{*} \PYG{n}{RMS}
\PYG{n}{spectrum} \PYG{o}{+}\PYG{o}{=} \PYG{n}{gaussian}\PYG{p}{(}\PYG{n}{AMP}\PYG{p}{,} \PYG{n}{FWHM}\PYG{p}{,} \PYG{n}{MEAN}\PYG{p}{)}\PYG{p}{(}\PYG{n}{chan}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Enter results into AGD dataset}
\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data\PYGZus{}list}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data\PYGZus{}list}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{spectrum}\PYG{p}{]}
\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x\PYGZus{}values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x\PYGZus{}values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{chan}\PYG{p}{]}
\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{errors}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{errors}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{errors}\PYG{p}{]}

\PYG{n}{pickle}\PYG{o}{.}\PYG{n}{dump}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{FILENAME}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{w}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}


\section{Running GaussPy}
\label{tutorial:running-gausspy}
With our simple dataset in hand, we can use GaussPy to decompose the spectrum
into Gaussian functions. To do this, we must specify the smoothing parameter
\(\alpha\) (see Behind the Scenes chapter for more details). For now, we
will guess a value of \(\log\alpha=1\). In later chapters
we will discuss training the AGD algorithm to select the optimal value of
\(\alpha\).

The following is an example code for running GaussPy. We will use the ``one-phase'' decomposition to begin with. We must specify the following parameters:
\begin{enumerate}
\item {} 
\code{alpha1}: our choice for the value of \(\log\alpha\).

\item {} 
\code{snr\_thresh}: the signal-to-noise ratio threshold below which amplitude GaussPy will not fit a component.

\item {} 
\code{FILENAME\_DATA}: the filename containing the dataset to-be-decomposed, constructed in the previous section (or any GaussPy-friendly dataset)

\item {} 
\code{FILENAME\_DATA\_DECOMP}: filename to store the decomposition results from GaussPy.

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Decompose simple dataset using AGD}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}
\PYG{k+kn}{import} \PYG{n+nn}{gausspy.gp} \PYG{k+kn}{as} \PYG{n+nn}{gp}

\PYG{c+c1}{\PYGZsh{} Specify necessary parameters}
\PYG{n}{alpha1} \PYG{o}{=} \PYG{l+m+mf}{1.}
\PYG{n}{snr\PYGZus{}thresh} \PYG{o}{=} \PYG{l+m+mf}{5.}
\PYG{n}{FILENAME\PYGZus{}DATA} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{simple\PYGZus{}gaussian.pickle}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}DECOMP} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{simple\PYGZus{}gaussian\PYGZus{}decomposed.pickle}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Load GaussPy}
\PYG{n}{g} \PYG{o}{=} \PYG{n}{gp}\PYG{o}{.}\PYG{n}{GaussianDecomposer}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Setting AGD parameters}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{phase}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{one}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SNR\PYGZus{}thresh}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{n}{snr\PYGZus{}thresh}\PYG{p}{,} \PYG{n}{snr\PYGZus{}thresh}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{alpha1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{alpha1}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Run GaussPy}
\PYG{n}{data\PYGZus{}decomp} \PYG{o}{=} \PYG{n}{g}\PYG{o}{.}\PYG{n}{batch\PYGZus{}decomposition}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Save decomposition information}
\PYG{n}{pickle}\PYG{o}{.}\PYG{n}{dump}\PYG{p}{(}\PYG{n}{data\PYGZus{}decomp}\PYG{p}{,} \PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}DECOMP}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{w}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

After AGD determines the Gaussian decomposition, GaussPy then performs a least squares fit of the inital AGD model to the data to produce a final fit solution. The file containing the fit results is a python pickle file. The contents of this file can be viewed by printing the keys within the saved dictionary via,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k}{print} \PYG{n}{data\PYGZus{}decomp}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

The most salient information included in this file are the values for the \code{amplitudes}, \code{fwhms} and \code{means} of each fitted Gaussian component. These include,
\begin{enumerate}
\item {} 
\code{amplitudes\_initial, fwhms\_initial, means\_initial} : the parameters of each Gaussian component determined by AGD (each array has length equal to the number of fitted components).

\item {} 
\code{amplitudes\_fit, fwhms\_fit, means\_fit} : the parameters of each Gaussian component following a least-squares fit of the initial AGD model to the data.

\item {} 
\code{amplitudes\_fit\_err, fwhms\_fit\_err, means\_fit\_err} : uncertainities in the fitted Gaussian parameters, determined from the least-squares fit.

\end{enumerate}

GaussPy also stores the reduced \(\chi^2\) value from the least-squares fit (\code{rchi2}), but this is currently under construction. This value can be computed outside of GaussPy easily.


\section{Plot Decomposition Results}
\label{tutorial:plot-decomposition-results}
The following is an example python script for plotting the original spectrum and GaussPy decomposition results. We must specify the following parameters:
\begin{enumerate}
\item {} 
\code{FILENAME\_DATA}: the filename containing the dataset to-be-decomposed.

\item {} 
\code{FILENAME\_DATA\_DECOMP}: the filename containing the GaussPy decomposition results.

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Plot GaussPy results}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib.pyplot} \PYG{k+kn}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}

\PYG{k}{def} \PYG{n+nf}{gaussian}\PYG{p}{(}\PYG{n}{amp}\PYG{p}{,} \PYG{n}{fwhm}\PYG{p}{,} \PYG{n}{mean}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{n}{amp} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{4.} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)} \PYG{o}{*} \PYG{p}{(}\PYG{n}{x}\PYG{o}{\PYGZhy{}}\PYG{n}{mean}\PYG{p}{)}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2} \PYG{o}{/} \PYG{n}{fwhm}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{)}

\PYG{k}{def} \PYG{n+nf}{unravel}\PYG{p}{(}\PYG{n+nb}{list}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{n}{i} \PYG{k}{for} \PYG{n}{array} \PYG{o+ow}{in} \PYG{n+nb}{list} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n}{array}\PYG{p}{]}\PYG{p}{)}

\PYG{n}{FILENAME\PYGZus{}DATA} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{simple\PYGZus{}gaussian.pickle}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}DECOMP} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{simple\PYGZus{}gaussian\PYGZus{}decomposed.pickle}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{n}{data} \PYG{o}{=} \PYG{n}{pickle}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{spectrum} \PYG{o}{=} \PYG{n}{unravel}\PYG{p}{(}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data\PYGZus{}list}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{chan} \PYG{o}{=} \PYG{n}{unravel}\PYG{p}{(}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x\PYGZus{}values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{errors} \PYG{o}{=} \PYG{n}{unravel}\PYG{p}{(}\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{errors}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{n}{data\PYGZus{}decomp} \PYG{o}{=} \PYG{n}{pickle}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}DECOMP}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{means\PYGZus{}fit} \PYG{o}{=} \PYG{n}{unravel}\PYG{p}{(}\PYG{n}{data\PYGZus{}decomp}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{means\PYGZus{}fit}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{amps\PYGZus{}fit} \PYG{o}{=} \PYG{n}{unravel}\PYG{p}{(}\PYG{n}{data\PYGZus{}decomp}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{amplitudes\PYGZus{}fit}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{fwhms\PYGZus{}fit} \PYG{o}{=} \PYG{n}{unravel}\PYG{p}{(}\PYG{n}{data\PYGZus{}decomp}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fwhms\PYGZus{}fit}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{n}{fig} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{ax} \PYG{o}{=} \PYG{n}{fig}\PYG{o}{.}\PYG{n}{add\PYGZus{}subplot}\PYG{p}{(}\PYG{l+m+mi}{111}\PYG{p}{)}

\PYG{n}{model} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{chan}\PYG{p}{)}\PYG{p}{)}

\PYG{k}{for} \PYG{n}{j} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{means\PYGZus{}fit}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{component} \PYG{o}{=} \PYG{n}{gaussian}\PYG{p}{(}\PYG{n}{amps\PYGZus{}fit}\PYG{p}{[}\PYG{n}{j}\PYG{p}{]}\PYG{p}{,} \PYG{n}{fwhms\PYGZus{}fit}\PYG{p}{[}\PYG{n}{j}\PYG{p}{]}\PYG{p}{,} \PYG{n}{means\PYGZus{}fit}\PYG{p}{[}\PYG{n}{j}\PYG{p}{]}\PYG{p}{)}\PYG{p}{(}\PYG{n}{chan}\PYG{p}{)}
    \PYG{n}{model} \PYG{o}{+}\PYG{o}{=} \PYG{n}{component}
    \PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{chan}\PYG{p}{,} \PYG{n}{component}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{red}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{lw}\PYG{o}{=}\PYG{l+m+mf}{1.5}\PYG{p}{)}

\PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{chan}\PYG{p}{,} \PYG{n}{spectrum}\PYG{p}{,} \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Data}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{black}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mf}{1.5}\PYG{p}{)}
\PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{chan}\PYG{p}{,} \PYG{n}{model}\PYG{p}{,} \PYG{n}{label} \PYG{o}{=} \PYG{l+s+s1}{r\PYGZsq{}}\PYG{l+s+s1}{\PYGZdl{}}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{log}\PYG{l+s+s1}{\PYGZbs{}}\PYG{l+s+s1}{alpha=1.\PYGZdl{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{purple}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mf}{2.}\PYG{p}{)}
\PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{chan}\PYG{p}{,} \PYG{n}{errors}\PYG{p}{,} \PYG{n}{label} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Errors}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{green}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{linestyle}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{dashed}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mf}{2.}\PYG{p}{)}

\PYG{n}{ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Channels}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Amplitude}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{n}{ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}xlim}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{chan}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}ylim}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{min}\PYG{p}{(}\PYG{n}{spectrum}\PYG{p}{)}\PYG{p}{,}\PYG{n}{np}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{n}{spectrum}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{ax}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{n}{loc}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}

\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

Fig. \hyperref[tutorial:simple-gaussian-decomposed]{ \ref*{tutorial:simple-gaussian-decomposed}} displays the results of the
decomposition using the above example python code. Clearly the fit to the simple
Gaussian spectrum is good. If we were to vary the value of \(\log\alpha\), the
fit would not change significantly as the fit to a spectrum containing a single
Gaussian funciton does not depend sensitively on the initial guesses, especially
because GaussPy performs a least-squares fit after determining initial guesses
for the fitted Gaussian parameters with AGD.
\begin{figure}[htbp]
\centering
\capstart

\includegraphics[width=5in]{{simple_gaussian_decomposed}.png}
\caption{Example spectrum containing a single Gaussian function with added spectral noise, decomposed using GaussPy.}\label{tutorial:simple-gaussian-decomposed}\end{figure}

In the ensuing chapters, we will move on from this simple example to consider spectra of increased complexity, as well as the effect of different values of \(\alpha\) on the decomposition.


\chapter{Multiple Gaussians Tutorial}
\label{tutorial:id2}\label{tutorial:multiple-gaussians-tutorial}

\section{Constructing a GaussPy-Friendly Dataset}
\label{tutorial:id3}
As discussed in the {\hyperref[tutorial:simple\string-example\string-tutorial]{\emph{Simple Example Tutorial}}}, before running GaussPy we
must ensure that our data is in a format readable by GaussPy. In particular, for
each spectrum, we need to provide the independent and dependent spectral arrays
(i.e. channels and amplitudes) and an estimate of the uncertainity per channel.
In the following example we will construct a spectrum containing multiple
overlapping Gaussian components with added spectral noise, using Equation
\eqref{tutorial-spectra}, and plot the results.

We will make the following choices for parameters in this example:
\begin{enumerate}
\item {} 
\code{NCOMPS = 3} : to include 3 Gaussian functions in the spectrum

\item {} 
\code{AMPS = {[}3,2,1{]}} : amplitudes of the included Gaussian functions

\item {} 
\code{FWHMS = {[}20,50,40{]}} : FWHM (in channels) of the included Gaussian functions

\item {} 
\code{MEANS = {[}220,250,300{]}} : mean positions (in channels) of the included Gaussian functions

\item {} 
\code{NCHANNELS = 512} : number of channels in the spectrum

\item {} 
\code{RMS = 0.05} : RMS noise per channel

\item {} 
\code{FILENAME} : name of file to write output data to

\end{enumerate}

The following code provides an example of how to construct a Gaussian function
with the above parameters and store it in GaussPy-friendly format.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Create profile with multiple, blended Gaussians and added noise}
\PYG{c+c1}{\PYGZsh{} Store in format required for GaussPy}

\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}

\PYG{k}{def} \PYG{n+nf}{gaussian}\PYG{p}{(}\PYG{n}{amp}\PYG{p}{,} \PYG{n}{fwhm}\PYG{p}{,} \PYG{n}{mean}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{n}{amp} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{4.} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)} \PYG{o}{*} \PYG{p}{(}\PYG{n}{x}\PYG{o}{\PYGZhy{}}\PYG{n}{mean}\PYG{p}{)}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2} \PYG{o}{/} \PYG{n}{fwhm}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Specify filename of output data}
\PYG{n}{FILENAME} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{multiple\PYGZus{}gaussians.pickle}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Number of Gaussian functions per spectrum}
\PYG{n}{NCOMPS} \PYG{o}{=} \PYG{l+m+mi}{3}

\PYG{c+c1}{\PYGZsh{} Component properties}
\PYG{n}{AMPS} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{n}{FWHMS} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{20}\PYG{p}{,}\PYG{l+m+mi}{50}\PYG{p}{,}\PYG{l+m+mi}{40}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} channels}
\PYG{n}{MEANS} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{220}\PYG{p}{,}\PYG{l+m+mi}{250}\PYG{p}{,}\PYG{l+m+mi}{300}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} channels}

\PYG{c+c1}{\PYGZsh{} Data properties}
\PYG{n}{RMS} \PYG{o}{=} \PYG{l+m+mf}{0.05}
\PYG{n}{NCHANNELS} \PYG{o}{=} \PYG{l+m+mi}{512}

\PYG{c+c1}{\PYGZsh{} Initialize}
\PYG{n}{data} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{chan} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{n}{NCHANNELS}\PYG{p}{)}
\PYG{n}{errors} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{n}{NCHANNELS}\PYG{p}{)} \PYG{o}{*} \PYG{n}{RMS}

\PYG{n}{spectrum} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{randn}\PYG{p}{(}\PYG{n}{NCHANNELS}\PYG{p}{)} \PYG{o}{*} \PYG{n}{RMS}

\PYG{c+c1}{\PYGZsh{} Create spectrum}
\PYG{k}{for} \PYG{n}{a}\PYG{p}{,} \PYG{n}{w}\PYG{p}{,} \PYG{n}{m} \PYG{o+ow}{in} \PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{AMPS}\PYG{p}{,} \PYG{n}{FWHMS}\PYG{p}{,} \PYG{n}{MEANS}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{spectrum} \PYG{o}{+}\PYG{o}{=} \PYG{n}{gaussian}\PYG{p}{(}\PYG{n}{a}\PYG{p}{,} \PYG{n}{w}\PYG{p}{,} \PYG{n}{m}\PYG{p}{)}\PYG{p}{(}\PYG{n}{chan}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Enter results into AGD dataset}
\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data\PYGZus{}list}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data\PYGZus{}list}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{spectrum}\PYG{p}{]}
\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x\PYGZus{}values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x\PYGZus{}values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{chan}\PYG{p}{]}
\PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{errors}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{errors}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{errors}\PYG{p}{]}

\PYG{n}{pickle}\PYG{o}{.}\PYG{n}{dump}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{FILENAME}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{w}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

A plot of the spectrum constructed above is included in Fig.
\hyperref[tutorial:multiple-gaussians]{ \ref*{tutorial:multiple-gaussians}}.
\begin{figure}[htbp]
\centering
\capstart

\includegraphics[width=5in]{{multiple_gaussians}.png}
\caption{Example spectrum containing multiple Gaussian functions with added spectral noise.}\label{tutorial:multiple-gaussians}\end{figure}


\section{Running GaussPy}
\label{tutorial:id4}
With our GaussPy-friendly dataset, we can now run GaussPy. As in the
{\hyperref[tutorial:simple\string-example\string-tutorial]{\emph{Simple Example Tutorial}}}, we begin by selecting a value of \(\alpha\)
to use in the decomposition. In this example, we will select \(\log\alpha=0.5\) to
begin with. As before, the important parameters to specify are:
\begin{enumerate}
\item {} 
\code{alpha1}: our choice for the value of \(\log\alpha\).

\item {} 
\code{snr\_thresh}: the signal-to-noise ratio threshold below which amplitude
GaussPy will not fit a component.

\item {} 
\code{FILENAME\_DATA}: the filename containing the dataset to-be-decomposed,
constructed above (or any GaussPy-friendly dataset)

\item {} 
\code{FILENAME\_DATA\_DECOMP}: the filename to store the decomposition results from
GaussPy.

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Decompose multiple Gaussian dataset using AGD}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}
\PYG{k+kn}{import} \PYG{n+nn}{gausspy.gp} \PYG{k+kn}{as} \PYG{n+nn}{gp}

\PYG{c+c1}{\PYGZsh{} Specify necessary parameters}
\PYG{n}{alpha1} \PYG{o}{=} \PYG{l+m+mf}{0.5}
\PYG{n}{snr\PYGZus{}thresh} \PYG{o}{=} \PYG{l+m+mf}{5.}
\PYG{n}{FILENAME\PYGZus{}DATA} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{multiple\PYGZus{}gaussians.pickle}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}DECOMP} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{multiple\PYGZus{}gaussians\PYGZus{}decomposed.pickle}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Load GaussPy}
\PYG{n}{g} \PYG{o}{=} \PYG{n}{gp}\PYG{o}{.}\PYG{n}{GaussianDecomposer}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Setting AGD parameters}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{phase}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{one}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SNR\PYGZus{}thresh}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{n}{snr\PYGZus{}thresh}\PYG{p}{,} \PYG{n}{snr\PYGZus{}thresh}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{alpha1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{alpha1}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Run GaussPy}
\PYG{n}{data\PYGZus{}decomp} \PYG{o}{=} \PYG{n}{g}\PYG{o}{.}\PYG{n}{batch\PYGZus{}decomposition}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Save decomposition information}
\PYG{n}{pickle}\PYG{o}{.}\PYG{n}{dump}\PYG{p}{(}\PYG{n}{data\PYGZus{}decomp}\PYG{p}{,} \PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}DECOMP}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{w}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}


\section{Plot Decomposition Results}
\label{tutorial:id5}
Following the decomposition by GaussPy, we can explore the effect of the choice
of \(\alpha\) on the decomposition. In Fig.
\hyperref[tutorial:multiple-gaussians-decomposed]{ \ref*{tutorial:multiple-gaussians-decomposed}}, we have run GaussPy on the
multiple-Gaussian dataset constructed above for three values of \(\alpha\),
including \(\log\alpha=0.5, \log\alpha = 2.5\) and \(\log\alpha=1.5\) and plotted the
results.
\begin{figure}[htbp]
\centering
\capstart

\includegraphics[width=7in]{{multiple_gaussians_decomposed}.png}
\caption{Example spectrum containing multiple Gaussian functions with added spectral noise, decomposed using GaussPy for three values of the smoothing parameter \(\log\alpha\).}\label{tutorial:multiple-gaussians-decomposed}\end{figure}

These results demonstrate that our choice of \(\alpha\) has a significant
effect on the success of the GaussPy model. In order to select the best value
of \(\alpha\) for a given dataset, we need to train the AGD algorithm using
a training set. This process is described in the following section.


\chapter{Training AGD}
\label{tutorial:training-agd}\label{tutorial:training-example}

\section{Creating a Synthetic Training Dataset}
\label{tutorial:creating-a-synthetic-training-dataset}
To select the optimal value of the smoothing parameter \(\alpha\), you must
train the AGD algorithm using a training dataset with known underlying Gaussian
decomposition. In other words, you need to have a dataset for which you know (or
have an estimate of) the true Gaussian model. This training dataset can be
composed of real (i.e. previously analyzed) or synthetically-constructed data,
for which you have prior information about the underlying decomposition. This
prior information is used to maximize the model accuracy by calibrating the
\(\alpha\) parameter used by AGD.

Training datasets can be constructed by adding Gaussian functions with
parameters drawn from known distributions with known uncertainties. For example,
we can create a mock dataset with \code{NSPECTRA}-realizations of Equation
\eqref{tutorial-spectra}.

In the next example we will show how to implement this in python. For this
example we will construct a synthetic training dataset with parameters similar
to those found in the {\hyperref[tutorial:multiple\string-gaussians\string-tutorial]{\emph{Multiple Gaussians Tutorial}}} example. We must set
the following parameters:
\begin{enumerate}
\item {} 
\(\mathrm{NOISE} \sim N(0, {\rm RMS}) + f \times {\rm RMS}\)
with \code{RMS=0.05} and \(f=0\)

\item {} 
\code{NCOMPS = 3}

\item {} 
\code{NCHANNELS = 512} : the number of channels per spectrum

\item {} 
\code{RMS = 0.05} : RMS noise per channel.

\item {} 
\code{NSPECTRA = 200} : number of synthetic spectra to create for the training dataset.

\end{enumerate}
\begin{enumerate}
\setcounter{enumi}{3}
\item {} 
\(\mathrm{AMP} \sim \mu(0.5, 4)\) : the possible range of amplitudes to be included in each synthetic spectrum. Spectra with a more dominant contribution
from the noise can also be generated and used as training sets for AGD.

\item {} 
\(\mathrm{FWHM} \sim \mu(20, 80)\) and \(\mathrm{MEAN}\sim \mu(0.25, 0.75) \times \mathrm{NCHANNELS}\) : the possible range of FWHM and mean positions of Gaussian functions to be included in each synthetic spectrum.

\item {} 
\code{TRAINING\_SET} : True, determines whether the decomposition ``true answers''
are sorted along with the synthetic spectra for accuracy verification in
training.

\item {} 
\code{FILENAME} : filename for storing the synthetically-constructed data

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Create training dataset with Gaussian profiles}

\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}

\PYG{c+c1}{\PYGZsh{} Specify the number of spectral channels (NCHANNELS)}
\PYG{n}{NCHANNELS} \PYG{o}{=} \PYG{l+m+mi}{512}

\PYG{c+c1}{\PYGZsh{} Specify the number of spectra (NSPECTRA)}
\PYG{n}{NSPECTRA} \PYG{o}{=} \PYG{l+m+mi}{200}

\PYG{c+c1}{\PYGZsh{} Estimate of the root\PYGZhy{}mean\PYGZhy{}square uncertainty per channel (RMS)}
\PYG{n}{RMS} \PYG{o}{=} \PYG{l+m+mf}{0.05}

\PYG{c+c1}{\PYGZsh{} Estimate the number of components}
\PYG{n}{NCOMPS} \PYG{o}{=} \PYG{l+m+mi}{3}

\PYG{c+c1}{\PYGZsh{} Specify the min\PYGZhy{}max range of possible properties of the Gaussian function paramters:}
\PYG{n}{AMP\PYGZus{}lims} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{]}
\PYG{n}{FWHM\PYGZus{}lims} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{20}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} channels}
\PYG{n}{MEAN\PYGZus{}lims} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mf}{0.25}\PYG{o}{*}\PYG{n}{NCHANNELS}\PYG{p}{,} \PYG{l+m+mf}{0.75}\PYG{o}{*}\PYG{n}{NCHANNELS}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} channels}

\PYG{c+c1}{\PYGZsh{} Indicate whether the data created here will be used as a training set}
\PYG{c+c1}{\PYGZsh{} (a.k.a. decide to store the \PYGZdq{}true\PYGZdq{} answers or not at the end)}
\PYG{n}{TRAINING\PYGZus{}SET} \PYG{o}{=} \PYG{n+nb+bp}{True}

\PYG{c+c1}{\PYGZsh{} Specify the pickle file to store the results in}
\PYG{n}{FILENAME} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{training\PYGZus{}data.pickle}\PYG{l+s+s1}{\PYGZsq{}}
\end{Verbatim}

With the above parameters specified, we can proceed with constructing a set of synthetic training data composed of Gaussian functions with known parameters (i.e., for which we know the ``true'' decompositon), sampled randomly from the parameter ranges specified above. The resulting data, including the channel values, spectral values and error estimates, are stored in the pickle file specified above with \code{FILENAME}. Because we want this to be a training set (\code{TRAINING\_SET = True}), the true decomposition answers (in the form of amplitudes, FWHM and means for all components) are also stored in the output file. For example, to construct a synthetic dataset:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Create training dataset with Gaussian profiles \PYGZhy{}cont\PYGZhy{}}

\PYG{c+c1}{\PYGZsh{} Initialize}
\PYG{n}{data} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{chan} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{n}{NCHANNELS}\PYG{p}{)}
\PYG{n}{errors} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{n}{NCHANNELS}\PYG{p}{)} \PYG{o}{*} \PYG{n}{RMS}

\PYG{c+c1}{\PYGZsh{} Begin populating data}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{NSPECTRA}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{spectrum\PYGZus{}i} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{randn}\PYG{p}{(}\PYG{n}{NCHANNELS}\PYG{p}{)} \PYG{o}{*} \PYG{n}{RMS}

    \PYG{n}{amps} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{n}{fwhms} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{n}{means} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}

    \PYG{k}{for} \PYG{n}{comp} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{NCOMPS}\PYG{p}{)}\PYG{p}{:}
        \PYG{c+c1}{\PYGZsh{} Select random values for components within specified ranges}
        \PYG{n}{a} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{uniform}\PYG{p}{(}\PYG{n}{AMP\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{AMP\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}
        \PYG{n}{w} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{uniform}\PYG{p}{(}\PYG{n}{FWHM\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{FWHM\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}
        \PYG{n}{m} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{uniform}\PYG{p}{(}\PYG{n}{MEAN\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{MEAN\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}

        \PYG{c+c1}{\PYGZsh{} Add Gaussian profile with the above random parameters to the spectrum}
        \PYG{n}{spectrum\PYGZus{}i} \PYG{o}{+}\PYG{o}{=} \PYG{n}{gaussian}\PYG{p}{(}\PYG{n}{a}\PYG{p}{,} \PYG{n}{w}\PYG{p}{,} \PYG{n}{m}\PYG{p}{)}\PYG{p}{(}\PYG{n}{chan}\PYG{p}{)}

        \PYG{c+c1}{\PYGZsh{} Append the parameters to initialized lists for storing}
        \PYG{n}{amps}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{a}\PYG{p}{)}
        \PYG{n}{fwhms}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{w}\PYG{p}{)}
        \PYG{n}{means}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{m}\PYG{p}{)}

    \PYG{c+c1}{\PYGZsh{} Enter results into AGD dataset}
    \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data\PYGZus{}list}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data\PYGZus{}list}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{spectrum\PYGZus{}i}\PYG{p}{]}
    \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x\PYGZus{}values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x\PYGZus{}values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{chan}\PYG{p}{]}
    \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{errors}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{errors}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{errors}\PYG{p}{]}

    \PYG{c+c1}{\PYGZsh{} If training data, keep answers}
    \PYG{k}{if} \PYG{n}{TRAINING\PYGZus{}SET}\PYG{p}{:}
        \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{amplitudes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{amplitudes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{amps}\PYG{p}{]}
        \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fwhms}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fwhms}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{fwhms}\PYG{p}{]}
        \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{means}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{means}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{means}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Dump synthetic data into specified filename}
\PYG{n}{pickle}\PYG{o}{.}\PYG{n}{dump}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{FILENAME}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{w}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}


\section{Training the Algorithm}
\label{tutorial:training-the-algorithm}
Next, we will apply GaussPy to the real or synthetic training dataset and compare the results with the known underlying decompositon to determine the optimal value for the smoothing parameter \(\alpha\). We must set the following parameters
\begin{enumerate}
\item {} 
\code{FILENAME}: the filename of the training dataset in GaussPy-friendly format.

\item {} 
\code{snr\_thresh}: the signal-to-noise threshold below which amplitude GaussPy will not fit components.

\item {} 
\code{alpha\_initial}: initial choice for \(\log\alpha\)

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Select the optimal value of alpha by training the AGD algorithm}

\PYG{k+kn}{import} \PYG{n+nn}{gausspy.gp} \PYG{k+kn}{as} \PYG{n+nn}{gp}

\PYG{c+c1}{\PYGZsh{} Set necessary parameters}
\PYG{n}{FILENAME} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{training\PYGZus{}data.pickle}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{snr\PYGZus{}thresh} \PYG{o}{=} \PYG{l+m+mf}{5.}
\PYG{n}{alpha\PYGZus{}initial} \PYG{o}{=} \PYG{l+m+mf}{1.}

\PYG{n}{g} \PYG{o}{=} \PYG{n}{gp}\PYG{o}{.}\PYG{n}{GaussianDecomposer}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Next, load the training dataset for analysis:}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{load\PYGZus{}training\PYGZus{}data}\PYG{p}{(}\PYG{n}{FILENAME}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Set GaussPy parameters}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{phase}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{one}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SNR\PYGZus{}thresh}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{n}{snr\PYGZus{}thresh}\PYG{p}{,} \PYG{n}{snr\PYGZus{}thresh}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Train AGD starting with initial guess for alpha}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{train}\PYG{p}{(}\PYG{n}{alpha1\PYGZus{}initial} \PYG{o}{=} \PYG{n}{alpha\PYGZus{}initial}\PYG{p}{)}
\end{Verbatim}

GausspPy will decompose the training dataset with the initial choice of \(\alpha_{\rm initial}\) and compare the results with the known underlying decomposition to compute the accuracy of the decomposition. The training process will then iteratively change the value of \(\alpha_{\rm initial}\) and recompute the decomposition until the process converges.The accuracy of the decomposition associated with the converged value of \(\alpha\) is a description of how well GaussPy can recover the true underlying decomposition.

The above training dataset parameters were selected with the {\hyperref[tutorial:multiple\string-gaussians\string-tutorial]{\emph{Multiple Gaussians Tutorial}}} in mind. As we saw in that example, the choice of \(\alpha\) has a significant effect on the GaussPy decomposition. In the training above, when we choose an initial value of \(\log\alpha_{\rm initial}=1.0\) the training process converges to \(\log\alpha=1.58\) with an accuracy of 68.4\%, and required 33 iterations.

To ensure that the training converges on the optimal value of \(\alpha\) and not a local maximum, it is useful to re-run the training process for several choices of \(\alpha_{\rm initial}\). When we run the above example with an initial choice of \(\log\alpha_{initial}=3\), AGD converges to a value of \(\log\alpha=1.58\) with an accuracy of 68.4\% and required 33 iterations. However, this is a relatively simple example and therefore the converged value of alpha is not very sensitive to \(\alpha_{\rm initial}\). In the Prepping a Datacube chapter, we will discuss the effects of added complexity.


\section{Running GaussPy using Trained \protect\(\alpha\protect\)}
\label{tutorial:running-gausspy-using-trained}
With a trained value of \(\alpha\) in hand, we can proceed to decompose our
target dataset with AGD. In this example, we will return to the example from the
{\hyperref[tutorial:multiple\string-gaussians\string-tutorial]{\emph{Multiple Gaussians Tutorial}}} chapter. Following training, we select a
value of \(\log\alpha=1.58\), which decomposed our training dataset with an
accuracy of 68.4\%. As in the {\hyperref[tutorial:simple\string-example\string-tutorial]{\emph{Simple Example Tutorial}}} and
{\hyperref[tutorial:multiple\string-gaussians\string-tutorial]{\emph{Multiple Gaussians Tutorial}}}, the important parameters to specify are:
\begin{enumerate}
\item {} 
\code{alpha1}: our choice for the value of \(\log\alpha\)

\item {} 
\code{snr\_thresh}: the signal-to-noise ratio threshold below which amplitude
GaussPy will not fit a component

\item {} 
\code{FILENAME\_DATA}: the filename containing the dataset to-be-decomposed,
constructed above (or any GaussPy-friendly dataset)

\item {} 
\code{FILENAME\_DATA\_DECOMP}: filename to store the decomposition results from
GaussPy

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Decompose multiple Gaussian dataset using AGD with TRAINED alpha}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}
\PYG{k+kn}{import} \PYG{n+nn}{gausspy.gp} \PYG{k+kn}{as} \PYG{n+nn}{gp}

\PYG{c+c1}{\PYGZsh{} Specify necessary parameters}
\PYG{n}{alpha1} \PYG{o}{=} \PYG{l+m+mf}{1.58}
\PYG{n}{snr\PYGZus{}thresh} \PYG{o}{=} \PYG{l+m+mf}{5.}

\PYG{n}{FILENAME\PYGZus{}DATA} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{multiple\PYGZus{}gaussians.pickle}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}DECOMP} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{multiple\PYGZus{}gaussians\PYGZus{}trained\PYGZus{}decomposed.pickle}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Load GaussPy}
\PYG{n}{g} \PYG{o}{=} \PYG{n}{gp}\PYG{o}{.}\PYG{n}{GaussianDecomposer}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Setting AGD parameters}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{phase}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{one}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SNR\PYGZus{}thresh}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{n}{snr\PYGZus{}thresh}\PYG{p}{,} \PYG{n}{snr\PYGZus{}thresh}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{alpha1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{alpha1}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Run GaussPy}
\PYG{n}{data\PYGZus{}decomp} \PYG{o}{=} \PYG{n}{g}\PYG{o}{.}\PYG{n}{batch\PYGZus{}decomposition}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Save decomposition information}
\PYG{n}{pickle}\PYG{o}{.}\PYG{n}{dump}\PYG{p}{(}\PYG{n}{data\PYGZus{}decomp}\PYG{p}{,} \PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}DECOMP}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{w}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

Fig. \hyperref[tutorial:multiple-gaussians-trained-decomposed]{ \ref*{tutorial:multiple-gaussians-trained-decomposed}} displays the result of
fitting the ``Multiple Gaussians'' spectrum with a trained value of
\(\log\alpha=1.58\).
\begin{figure}[htbp]
\centering

\includegraphics[width=7in]{{multiple_gaussians_trained_decomposed}.png}
\label{tutorial:multiple-gaussians-trained-decomposed}\end{figure}


\chapter{Two-Phase Decompositon}
\label{tutorial:two-phase-decomposition}\label{tutorial:two-phase-decompositon}
In the {\hyperref[tutorial:training\string-example]{\emph{Training AGD}}} chapter, we learned how to ``train'' AGD to select
the optimal value of the smoothing parameter \(\alpha\) using a training
dataset with known underlying decomposition. This trained value is essentially
tuned to find a particular type of Gaussian shape within the data. However, when
more than one family or phase of Gaussian shapes is contained within a spectrum,
one value of \(\alpha\) is not enough to recover all important spectral
information. For example, in radio astronomical observations of absorption by
neutral hydrogen at 21 cm, we find narrow and strong lines in addition to wide,
shallow lines indicative of two different populations of material, namely the
cold and warm neutral media.

For GaussPy to be sensitive to two types of Gaussian functions contained within
a dataset, we must use the ``two-phase'' version of AGD. The two-phase
decomposition makes use of two values of the smoothing parameter \(\alpha\),
one for each ``phase'' contained within the dataset.


\section{Training for Two Phases: \protect\(\alpha_1\protect\) and \protect\(\alpha_2\protect\)}
\label{tutorial:training-for-two-phases-and}
Using the example from the {\hyperref[tutorial:multiple\string-gaussians\string-tutorial]{\emph{Multiple Gaussians Tutorial}}}, we will train AGD
to allow for two different values of \(\alpha\). This gives GaussPy enough
flexibilty to use appropriate values of \(\alpha\) to fit both narrow and
wide features simultaneously. We will use the same training dataset constructed
in {\hyperref[tutorial:training\string-example]{\emph{Training AGD}}}. We must set the following parameters:
\begin{enumerate}
\item {} 
\code{FILENAME\_TRAIN}: the filename of the training dataset in GaussPy-friendly
format

\item {} 
\code{snr\_thresh}: the signal-to-noise threshold below which amplitude GaussPy
will not fit components

\item {} 
\code{alpha1\_initial, alpha2\_initial{}`}: initial choices for \(\log\alpha_1\) and
\(\log\alpha_2\)

\end{enumerate}

The training will be the same as in {\hyperref[tutorial:training\string-example]{\emph{Training AGD}}}, however we will set
the GaussPy parameter \emph{phase} equal to \emph{two} instead of \emph{one} to indicate that
we would like to solve for two different values of \(\alpha\).

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Select the optimal value of alpha by training the AGD algorithm}

\PYG{k+kn}{import} \PYG{n+nn}{gausspy.gp} \PYG{k+kn}{as} \PYG{n+nn}{gp}

\PYG{c+c1}{\PYGZsh{} Set necessary parameters}
\PYG{n}{FILENAME\PYGZus{}TRAIN} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{training\PYGZus{}data.pickle}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{snr\PYGZus{}thresh} \PYG{o}{=} \PYG{l+m+mf}{5.}
\PYG{n}{alpha1\PYGZus{}initial} \PYG{o}{=} \PYG{l+m+mf}{0.5}
\PYG{n}{alpha2\PYGZus{}initial} \PYG{o}{=} \PYG{l+m+mf}{2.}

\PYG{n}{g} \PYG{o}{=} \PYG{n}{gp}\PYG{o}{.}\PYG{n}{GaussianDecomposer}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Next, load the training dataset for analysis:}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{load\PYGZus{}training\PYGZus{}data}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}TRAIN}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Set GaussPy parameters}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{phase}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{two}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SNR\PYGZus{}thresh}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{n}{snr\PYGZus{}thresh}\PYG{p}{,} \PYG{n}{snr\PYGZus{}thresh}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Train AGD starting with initial guess for alpha}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{train}\PYG{p}{(}\PYG{n}{alpha1\PYGZus{}initial} \PYG{o}{=} \PYG{n}{alpha1\PYGZus{}initial}\PYG{p}{,} \PYG{n}{alpha2\PYGZus{}initial} \PYG{o}{=} \PYG{n}{alpha2\PYGZus{}initial}\PYG{p}{)}
\end{Verbatim}

Following training, GaussPy converges on values of \(\log\alpha_1 = 0.39\) and
\(\log\alpha_2 = 2.32\) in 39 iterations, with an accuracy of 76.0\%. Clearly,
the two-phase decomposition improves the accuracy of the decomposition, of
course at the expense of introducing a second free parameter in the
decomposition. In general, for datasets containing more than one type of
component (corresponding to different physical sources, for example), two-phase
decomposition will maximize the decompositon accuracy.


\chapter{Prepping a Datacube}
\label{dataprep:prepping-a-datacube}\label{dataprep:dataprep}\label{dataprep::doc}
In this example we will download a datacube to decompose into individual
spectra. The example cube we will use is from the GALFA-HI emission survey at
the Arecibo Observatory, specifically the \href{https://sites.google.com/site/galfahi/data}{M33 datacube} from \href{http://adsabs.harvard.edu/abs/2009ApJ...703.1486P}{Putman et al. 2009}. You can directly download
the cube from here:

\href{http://www.astro.columbia.edu/~mputman/M33only.fits.gz}{http://www.astro.columbia.edu/\textasciitilde{}mputman/M33only.fits.gz}


\section{Storing Data cube in GaussPy-Friendly Format}
\label{dataprep:storing-data-cube-in-gausspy-friendly-format}
Before decomposing the datacube, we must store the data in a format readable by
GaussPy. The following code provides an example of how to read a fits-formatted
datacube and store the spectral information. The necessary parameters to specify
here are:
\begin{enumerate}
\item {} 
\code{FILENAME\_DATA}: the fits filename of the target data cube

\item {} 
\code{FILENAME\_DATA\_GAUSSPY}: the filename to store the GaussPy-friendly data in

\item {} 
\code{RMS}: estimate of the RMS uncertainty per channel for constructing the
error arrays

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Read fits datacube and save in GaussPy format}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}
\PYG{k+kn}{from} \PYG{n+nn}{astropy.io} \PYG{k+kn}{import} \PYG{n}{fits}

\PYG{c+c1}{\PYGZsh{} Specify necessary parameters}
\PYG{n}{FILENAME\PYGZus{}DATA} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{M33only.fits}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}GAUSSPY} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{cube.pickle}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{RMS} \PYG{o}{=} \PYG{l+m+mf}{0.06}

\PYG{n}{hdu\PYGZus{}list} \PYG{o}{=} \PYG{n}{fits}\PYG{o}{.}\PYG{n}{open}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA}\PYG{p}{)}
\PYG{n}{hdu} \PYG{o}{=} \PYG{n}{hdu\PYGZus{}list}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{n}{cube} \PYG{o}{=} \PYG{n}{hdu}\PYG{o}{.}\PYG{n}{data}

\PYG{c+c1}{\PYGZsh{} initialize}
\PYG{n}{data} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{errors} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{n}{cube}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)} \PYG{o}{*} \PYG{n}{RMS}
\PYG{n}{chan} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{n}{cube}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} cycle through each spectrum}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{xrange}\PYG{p}{(}\PYG{n}{cube}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{for} \PYG{n}{j} \PYG{o+ow}{in} \PYG{n+nb}{xrange}\PYG{p}{(}\PYG{n}{cube}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{)}\PYG{p}{:}

        \PYG{c+c1}{\PYGZsh{} get the spectrum}
        \PYG{n}{spectrum} \PYG{o}{=} \PYG{n}{cube}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{n}{i}\PYG{p}{,} \PYG{n}{j}\PYG{p}{]}

        \PYG{c+c1}{\PYGZsh{} get the spectrum location}
        \PYG{n}{location} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{(}\PYG{n}{i}\PYG{p}{,} \PYG{n}{j}\PYG{p}{)}\PYG{p}{)}

        \PYG{c+c1}{\PYGZsh{} Enter results into GaussPy\PYGZhy{}friendly dataset}
        \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data\PYGZus{}list}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data\PYGZus{}list}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{spectrum}\PYG{p}{]}
        \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x\PYGZus{}values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x\PYGZus{}values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{chan}\PYG{p}{]}
        \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{errors}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{errors}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{errors}\PYG{p}{]}
        \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{location}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{location}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{location}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Save decomposition information}
\PYG{n}{pickle}\PYG{o}{.}\PYG{n}{dump}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}GAUSSPY}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{w}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

The output pickle file from the above example code contains a python dictionary
with four keys, including the independent and dependent arrays (i.e. channels
and spectral values), an array per spectrum describing the uncertainty per
channel, and the (x,y) pixel location within the datacube for reference.


\section{Creating a Synthetic Training Dataset}
\label{dataprep:creating-a-synthetic-training-dataset}
Before decomposing the target dataset, we need to train the AGD algorithm to
select the best values of \(\log\alpha\) in two-phase decomposition. First, we
construct a synthetic training dataset composed of Gaussian components with
parameters sampled randomly from ranges that represent the data as closely as
possible.
\begin{enumerate}
\item {} 
\code{RMS}: root mean square uncertainty per channel

\item {} 
\code{NCHANNELS}: number of channels per spectrum

\item {} 
\code{NSPECTRA}: number of spectra to include in the training dataset

\item {} 
\code{NCOMPS\_lims}: range in total number of components to include in each
spectrum

\item {} 
\code{AMP\_lims, FWHM\_lims, MEAN\_lims}: range of possible Gaussian component
values, amplitudes, FWHM and means, from which to build the spectra

\item {} 
\code{TRAINING\_SET} : True or False, determines whether the decomposition
``answers'' are stored along with the data for accuracy verification in
training

\item {} 
\code{FILENAME\_TRAIN} : filename for storing the training data

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Create training dataset with Gaussian profile}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}

\PYG{k}{def} \PYG{n+nf}{gaussian}\PYG{p}{(}\PYG{n}{amp}\PYG{p}{,} \PYG{n}{fwhm}\PYG{p}{,} \PYG{n}{mean}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{n}{amp} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{4.} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)} \PYG{o}{*} \PYG{p}{(}\PYG{n}{x}\PYG{o}{\PYGZhy{}}\PYG{n}{mean}\PYG{p}{)}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2} \PYG{o}{/} \PYG{n}{fwhm}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Estimate of the root\PYGZhy{}mean\PYGZhy{}square uncertainty per channel (RMS)}
\PYG{n}{RMS} \PYG{o}{=} \PYG{l+m+mf}{0.06}

\PYG{c+c1}{\PYGZsh{} Specify the number of spectral channels (NCHANNELS)}
\PYG{n}{NCHANNELS} \PYG{o}{=} \PYG{l+m+mi}{680}

\PYG{c+c1}{\PYGZsh{} Specify the number of spectra (NSPECTRA)}
\PYG{n}{NSPECTRA} \PYG{o}{=} \PYG{l+m+mi}{200}

\PYG{c+c1}{\PYGZsh{} Estimate the number of components}
\PYG{n}{NCOMPS\PYGZus{}lims} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Specify the min\PYGZhy{}max range of possible properties of the Gaussian function paramters:}
\PYG{n}{AMP\PYGZus{}lims} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mi}{30}\PYG{p}{]}
\PYG{n}{FWHM\PYGZus{}lims} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{20}\PYG{p}{,}\PYG{l+m+mi}{150}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} channels}
\PYG{n}{MEAN\PYGZus{}lims} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{400}\PYG{p}{,}\PYG{l+m+mi}{600}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} channels}

\PYG{c+c1}{\PYGZsh{} Indicate whether the data created here will be used as a training set}
\PYG{c+c1}{\PYGZsh{} (a.k.a. decide to store the \PYGZdq{}true\PYGZdq{} answers or not at the end)}
\PYG{n}{TRAINING\PYGZus{}SET} \PYG{o}{=} \PYG{n+nb+bp}{True}

\PYG{c+c1}{\PYGZsh{} Specify the pickle file to store the results in}
\PYG{n}{FILENAME\PYGZus{}TRAIN} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{cube\PYGZus{}training\PYGZus{}data.pickle}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Initialize}
\PYG{n}{data} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{chan} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{n}{NCHANNELS}\PYG{p}{)}
\PYG{n}{errors} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{n}{NCHANNELS}\PYG{p}{)} \PYG{o}{*} \PYG{n}{RMS}

\PYG{c+c1}{\PYGZsh{} Begin populating data}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{NSPECTRA}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{spectrum\PYGZus{}i} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{randn}\PYG{p}{(}\PYG{n}{NCHANNELS}\PYG{p}{)} \PYG{o}{*} \PYG{n}{RMS}

    \PYG{n}{amps} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{n}{fwhms} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{n}{means} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}

    \PYG{n}{ncomps} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{choice}\PYG{p}{(}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{n}{NCOMPS\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}\PYG{n}{NCOMPS\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}

    \PYG{k}{for} \PYG{n}{comp} \PYG{o+ow}{in} \PYG{n+nb}{xrange}\PYG{p}{(}\PYG{n}{ncomps}\PYG{p}{)}\PYG{p}{:}
        \PYG{c+c1}{\PYGZsh{} Select random values for components within specified ranges}
        \PYG{n}{a} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{uniform}\PYG{p}{(}\PYG{n}{AMP\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{AMP\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}
        \PYG{n}{w} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{uniform}\PYG{p}{(}\PYG{n}{FWHM\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{FWHM\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}
        \PYG{n}{m} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{uniform}\PYG{p}{(}\PYG{n}{MEAN\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{MEAN\PYGZus{}lims}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}

        \PYG{c+c1}{\PYGZsh{} Add Gaussian profile with the above random parameters to the spectrum}
        \PYG{n}{spectrum\PYGZus{}i} \PYG{o}{+}\PYG{o}{=} \PYG{n}{gaussian}\PYG{p}{(}\PYG{n}{a}\PYG{p}{,} \PYG{n}{w}\PYG{p}{,} \PYG{n}{m}\PYG{p}{)}\PYG{p}{(}\PYG{n}{chan}\PYG{p}{)}

        \PYG{c+c1}{\PYGZsh{} Append the parameters to initialized lists for storing}
        \PYG{n}{amps}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{a}\PYG{p}{)}
        \PYG{n}{fwhms}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{w}\PYG{p}{)}
        \PYG{n}{means}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{m}\PYG{p}{)}

    \PYG{c+c1}{\PYGZsh{} Enter results into AGD dataset}
    \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data\PYGZus{}list}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data\PYGZus{}list}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{spectrum\PYGZus{}i}\PYG{p}{]}
    \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x\PYGZus{}values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x\PYGZus{}values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{chan}\PYG{p}{]}
    \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{errors}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{errors}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{errors}\PYG{p}{]}

    \PYG{c+c1}{\PYGZsh{} If training data, keep answers}
    \PYG{k}{if} \PYG{n}{TRAINING\PYGZus{}SET}\PYG{p}{:}
        \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{amplitudes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{amplitudes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{amps}\PYG{p}{]}
        \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fwhms}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fwhms}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{fwhms}\PYG{p}{]}
        \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{means}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{get}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{means}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{p}{[}\PYG{n}{means}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} Dump synthetic data into specified filename}
\PYG{n}{pickle}\PYG{o}{.}\PYG{n}{dump}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}TRAIN}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{w}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}


\section{Training AGD to Select \protect\(\alpha\protect\) values}
\label{dataprep:training-agd-to-select-values}
With a synthetic training dataset in hand, we train AGD to select two values of
\(\log\alpha\) for the two-phase decomposition, \(\log\alpha_1\) and
\(\log\alpha_2\). The necessary parameters to specify are:
\begin{enumerate}
\item {} 
\code{FILENAME\_TRAIN}: the pickle file containing the training dataset in GaussPy
format

\item {} 
\code{snr\_thresh}: the signal to noise ratio below which GaussPy will not fit a
component

\item {} 
\code{alpha1\_initial, alpha2\_initial} initial choices of the two \(\log\alpha\)
parameters

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Train AGD using synthetic dataset}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}
\PYG{k+kn}{import} \PYG{n+nn}{gausspy.gp} \PYG{k+kn}{as} \PYG{n+nn}{gp}
\PYG{n+nb}{reload}\PYG{p}{(}\PYG{n}{gp}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Set necessary parameters}
\PYG{n}{FILENAME\PYGZus{}TRAIN} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{cube\PYGZus{}training\PYGZus{}data.pickle}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{snr\PYGZus{}thresh} \PYG{o}{=} \PYG{l+m+mf}{5.}
\PYG{n}{alpha1\PYGZus{}initial} \PYG{o}{=} \PYG{l+m+mi}{4}
\PYG{n}{alpha2\PYGZus{}initial} \PYG{o}{=} \PYG{l+m+mi}{12}

\PYG{n}{g} \PYG{o}{=} \PYG{n}{gp}\PYG{o}{.}\PYG{n}{GaussianDecomposer}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Next, load the training dataset for analysis:}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{load\PYGZus{}training\PYGZus{}data}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}TRAIN}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Set GaussPy parameters}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{phase}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{two}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SNR\PYGZus{}thresh}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{n}{snr\PYGZus{}thresh}\PYG{p}{,} \PYG{n}{snr\PYGZus{}thresh}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Train AGD starting with initial guess for alpha}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{train}\PYG{p}{(}\PYG{n}{alpha1\PYGZus{}initial} \PYG{o}{=} \PYG{n}{alpha1\PYGZus{}initial}\PYG{p}{,} \PYG{n}{alpha2\PYGZus{}initial} \PYG{o}{=} \PYG{n}{alpha2\PYGZus{}initial}\PYG{p}{)}
\end{Verbatim}

Training: starting with values of \(\log\alpha_{1,\rm \, initial}=3\) and
\(\log\alpha_{2,\rm \, initial}=12\), the training process converges to
\(\log\alpha_1=2.87\) and \(\log\alpha_2=10.61\) with an accuracy of 71.2\%
within 90 iterations.


\section{Decomposing the Datacube}
\label{dataprep:decomposing-the-datacube}
With the trained values in hand, we now decompose the target dataset:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Decompose multiple Gaussian dataset using AGD with TRAINED alpha}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}
\PYG{k+kn}{import} \PYG{n+nn}{gausspy.gp} \PYG{k+kn}{as} \PYG{n+nn}{gp}

\PYG{c+c1}{\PYGZsh{} Specify necessary parameters}
\PYG{n}{alpha1} \PYG{o}{=} \PYG{l+m+mf}{2.87}
\PYG{n}{alpha2} \PYG{o}{=} \PYG{l+m+mf}{10.61}
\PYG{n}{snr\PYGZus{}thresh} \PYG{o}{=} \PYG{l+m+mf}{5.0}

\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}GAUSSPY} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{cube.pickle}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}DECOMP} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{cube\PYGZus{}decomposed.pickle}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{c+c1}{\PYGZsh{} Load GaussPy}
\PYG{n}{g} \PYG{o}{=} \PYG{n}{gp}\PYG{o}{.}\PYG{n}{GaussianDecomposer}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Setting AGD parameters}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{phase}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{two}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{SNR\PYGZus{}thresh}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{p}{[}\PYG{n}{snr\PYGZus{}thresh}\PYG{p}{,} \PYG{n}{snr\PYGZus{}thresh}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{alpha1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{alpha1}\PYG{p}{)}
\PYG{n}{g}\PYG{o}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{alpha2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{alpha2}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Run GaussPy}
\PYG{n}{decomposed\PYGZus{}data} \PYG{o}{=} \PYG{n}{g}\PYG{o}{.}\PYG{n}{batch\PYGZus{}decomposition}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}GAUSSPY}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Save decomposition information}
\PYG{n}{pickle}\PYG{o}{.}\PYG{n}{dump}\PYG{p}{(}\PYG{n}{decomposed\PYGZus{}data}\PYG{p}{,} \PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}DECOMP}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{w}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

And plot the results for an example set of 9 spectra, randomly selected, to see
how well the decomposition went.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Plot GaussPy results for selections of cube LOS}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib.pyplot} \PYG{k+kn}{as} \PYG{n+nn}{plt}

\PYG{c+c1}{\PYGZsh{} load the original data}
\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}GAUSSPY} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{cube.pickle}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{pickle}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}GAUSSPY}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} load decomposed data}
\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}DECOMP} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{cube\PYGZus{}decomposed.pickle}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{data\PYGZus{}decomposed} \PYG{o}{=} \PYG{n}{pickle}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{n+nb}{open}\PYG{p}{(}\PYG{n}{FILENAME\PYGZus{}DATA\PYGZus{}DECOMP}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{index\PYGZus{}values} \PYG{o}{=}  \PYG{n}{np}\PYG{o}{.}\PYG{n}{argsort}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{randn}\PYG{p}{(}\PYG{l+m+mi}{5000}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} plot random results}
\PYG{n}{fig} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{p}{[}\PYG{l+m+mi}{9}\PYG{p}{,}\PYG{l+m+mi}{9}\PYG{p}{]}\PYG{p}{)}

\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{9}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{ax} \PYG{o}{=} \PYG{n}{fig}\PYG{o}{.}\PYG{n}{add\PYGZus{}subplot}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{n}{i}\PYG{p}{)}

    \PYG{n}{index} \PYG{o}{=} \PYG{n}{index\PYGZus{}values}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}
    \PYG{n}{x} \PYG{o}{=} \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x\PYGZus{}values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{n}{index}\PYG{p}{]}
    \PYG{n}{y} \PYG{o}{=} \PYG{n}{data}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data\PYGZus{}list}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{n}{index}\PYG{p}{]}

    \PYG{n}{fit\PYGZus{}fwhms} \PYG{o}{=} \PYG{n}{data\PYGZus{}decomposed}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{fwhms\PYGZus{}fit}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{n}{index}\PYG{p}{]}
    \PYG{n}{fit\PYGZus{}means} \PYG{o}{=} \PYG{n}{data\PYGZus{}decomposed}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{means\PYGZus{}fit}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{n}{index}\PYG{p}{]}
    \PYG{n}{fit\PYGZus{}amps} \PYG{o}{=} \PYG{n}{data\PYGZus{}decomposed}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{amplitudes\PYGZus{}fit}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{n}{index}\PYG{p}{]}

    \PYG{c+c1}{\PYGZsh{} Plot individual components}
    \PYG{k}{if} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{fit\PYGZus{}amps}\PYG{p}{)} \PYG{o}{\PYGZgt{}} \PYG{l+m+mf}{0.}\PYG{p}{:}
        \PYG{k}{for} \PYG{n}{j} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{fit\PYGZus{}amps}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
            \PYG{n}{amp}\PYG{p}{,} \PYG{n}{fwhm}\PYG{p}{,} \PYG{n}{mean} \PYG{o}{=}  \PYG{n}{fit\PYGZus{}amps}\PYG{p}{[}\PYG{n}{j}\PYG{p}{]}\PYG{p}{,} \PYG{n}{fit\PYGZus{}fwhms}\PYG{p}{[}\PYG{n}{j}\PYG{p}{]}\PYG{p}{,} \PYG{n}{fit\PYGZus{}means}\PYG{p}{[}\PYG{n}{j}\PYG{p}{]}
            \PYG{n}{yy} \PYG{o}{=} \PYG{n}{amp} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{4.} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)} \PYG{o}{*} \PYG{p}{(}\PYG{n}{x}\PYG{o}{\PYGZhy{}}\PYG{n}{mean}\PYG{p}{)}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2} \PYG{o}{/} \PYG{n}{fwhm}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{)}
            \PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{yy}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZhy{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{lw}\PYG{o}{=}\PYG{l+m+mf}{1.5}\PYG{p}{,}\PYG{n}{color}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{purple}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

    \PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{black}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}xlim}\PYG{p}{(}\PYG{l+m+mi}{400}\PYG{p}{,}\PYG{l+m+mi}{600}\PYG{p}{)}
    \PYG{n}{ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Channels}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{T\PYGZus{}B (K)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

Fig. \hyperref[dataprep:cube-decomposed]{ \ref*{dataprep:cube-decomposed}} displays an example set of spectra from the data
cube and the GaussPy decomposition using trained values of \(\log\alpha_1=2.87\)
and \(\log\alpha_2=10.61\).
\begin{figure}[htbp]
\centering
\capstart

\includegraphics[width=6in]{{cube_decomposed}.png}
\caption{Example spectra from the GALFA-HI M33 datacube, decomposed by GaussPy following two-phase training.}\label{dataprep:cube-decomposed}\end{figure}


\chapter{Behind the Scenes}
\label{method::doc}\label{method:method}\label{method:behind-the-scenes}

\section{Basic concepts}
\label{method:basic-concepts}
\code{GaussPy} is a Python implementation of the AGD algorithm described
in \href{http://iopscience.iop.org/article/10.1088/0004-6256/149/4/138/meta}{Lindner et al. (2015), AJ, 149, 138}. At
its core, AGD is a fast, automatic, extremely versatile way of
providing initial guesses for fitting Gaussian components to a
function of the form \(f(x) + n(x)\), where \(n(x)\) is a term
modeling possible contributions from noise. It is important to
emphasize here that although we use terminology coming from
radio-astronomy all the ideas upon which the code is founded can be
applied to any function of this form, moreover, non-Gaussian
components can also be in principle extracted with our methodology,
something we will include in a future release of the code.

Ideally, if blending of components was not an issue and \(n(x)=0\)
the task of fitting Gaussians to a given spectrum would be reduced to
find local maxima of \(f(x)\). However, both of these assumptions
dramatically fail in practical applications, where blending of lines
is an unavoidable issue and noise is intrinsic to the process of data
acquisition. In that case, looking for solutions of \({\rm
d}f(x)/{\rm d}x = 0\) is not longer a viable route to find local
extrema of \(f(x)\), instead a different approach must be taken.

AGD uses the fact that a local maximum in \(f(x)\) is also a local
minimum in the curvature. That is, the algorithm looks for points
\(x^*\) for which the following conditions are satisfied.
\begin{itemize}
\item {} 
The function \(f(x)\) has a non-trivial value

\end{itemize}
\phantomsection\label{method:equation-f0const}\begin{gather}
\begin{split}f(x^*) > \epsilon_0.\end{split}\label{method-f0const}
\end{gather}
In an ideal situation where the contribution from noise vanishes we
can take \(\epsilon_0=0\). However, when random fluctuations are
added to the target function, this condition needs to be modified
accordingly. A good selection of \(\epsilon_0\) thus needs to be
in proportion to the RMS of the analyzed signal.
\begin{itemize}
\item {} 
Next we require that the function \(f(x)\) has a ``bump'' in
\(x^*\)

\end{itemize}
\phantomsection\label{method:equation-f2const}\begin{gather}
\begin{split}\left.\frac{{\rm d}^2f}{{\rm d}x^2}\right|_{x=x^*}  < 0,\end{split}\label{method-f2const}
\end{gather}
this selection of the inequality ensures also that such feature has
negative curvature, or equivalently, that the point \(x^*\) is
candidate for being the position of a local maximum of
\(f(x)\). Note however that this is not a sufficient condition, we
also need to ensure that the curvature has a minimum at this location.
\begin{itemize}
\item {} 
This is achieved by imposing two additional constraints on
\(f(x)\)

\end{itemize}
\phantomsection\label{method:equation-f3const}\begin{gather}
\begin{split}\left.\frac{{\rm d}^3f}{{\rm d}x^3}\right|_{x=x^*} = 0\end{split}\label{method-f3const}
\end{gather}\phantomsection\label{method:equation-f4const}\begin{gather}
\begin{split}\left.\frac{{\rm d}^4f}{{\rm d}x^4}\right|_{x=x^*} > 0\end{split}\label{method-f4const}
\end{gather}
These 4 constraints then ensure that the point \(x^*\) is a local
minimum of the curvature. Furthermore, even in the presence of both
blending and noise, these expressions will yield the location of all
the points that are possible candidates for the positions of Gaussian
components in the target function. Fig. \hyperref[method:curvature]{ \ref*{method:curvature}} is an
example of a function defined as the sum of three gaussians for which
the conditions Eq. \eqref{method-f0const} - \eqref{method-f4const} are satisfied and the
local minima of curvature are successfully found, even when blending
of components is relevant.
\begin{figure}[htbp]
\centering
\capstart

\includegraphics[width=4in]{{curvature}.png}
\caption{Example of the points of negative curvature of the function
\(f(x)\). In this case \(f(x)\) is the sum of three
independent Gaussian functions (top). The vertical lines in each
panel show the conditions imposed on the derivatives to define the
points \(x^*\).}\label{method:curvature}\end{figure}


\section{Dealing with noise}
\label{method:dealing-with-noise}
The numeral problem related to the solution shown in the previous
section comes from the fact that calculating Eq. \eqref{method-f2const} -
\eqref{method-f4const} is not trivial in the presence of noise. For instance,
if the top panel of Fig. \hyperref[method:curvature]{ \ref*{method:curvature}} is sampled with 100
channels, and in each panel a random uncorrelated noise component is
added at the 10\% level, a simple finite difference prescription to
calculate the derivative would lead to variations of the order
\(\sim 1 / {\rm d}x \sim 10\). That is, the signal would be buried
within the noise!
\begin{figure}[htbp]
\centering
\capstart

\includegraphics[width=4in]{{deriv}.png}
\caption{The top panel shows the same function used in
Fig. \hyperref[method:curvature]{ \ref*{method:curvature}} but now random noise has been added to each
channel. In the bottom panel we show various estimates of the
first derivative. \(\alpha=0\) corresponds to the finite
differences method, larger values of \(\alpha\) makes the
function smoother.}\label{method:deriv}\end{figure}

In order to solve this problem AGD uses a regularized version of the
derivative (\href{http://www.amazon.com/Computational-Methods-Problems-Frontiers-Mathematics/dp/0898715075}{Vogel (2002)}). If
\(u = {\rm d}f(x)/{\rm d}x\), then the problem we solve is
\(u = {\rm arg}\min_u\{R[u]\}\) where \(R[u]\) is the
functional defined by
\phantomsection\label{method:equation-deriv}\begin{gather}
\begin{split}R[u] = \int | A u - f | + \alpha \int \sqrt{(Du)^2 +
       \beta^2},\end{split}\label{method-deriv}
\end{gather}
where \(A u = \int {\rm d}x\; u\). Note that if \(\alpha=0\)
this is equivalent to find the derivative of the function
\(f(x)\), since we will be minimizing the difference between the
integral of \(u = {\rm d}f(x)/{\rm d}x\) and \(f(x)\)
itself. This, however, has the problem we discussed in the previous
paragraph. Fig. \hyperref[method:deriv]{ \ref*{method:deriv}} shows this case, it is clear that this
simple approach fails to recover the behavior of the target
function. If, on the other hand, \(\alpha > 0\) an additional
weight is added to the inverse problem in Eq. \eqref{method-deriv}, now the
differences between successive points in \(u(x)\) are taken into
account.

The parameter \(\alpha\) then controls how smooth the derivative
is going to be. The risk here is that overshooting the value of this
number can erase the intrinsic variations of the actual
derivative. What is the optimal value of \(\alpha\)? This question
is answered by \code{GaussPy} through the training process of the
algorithm. We refer the reader to the example chapters to learn how to
use this feature.


\section{Two phases}
\label{method:two-phases}
Within \code{GaussPy} is built-in the ability to automatically choose the
best value of \(\alpha\) for any input data set. Special caution
has to be taken here. If a component is too narrow it can be confused
with noise and smoothed away by the algorithm!

In order to circumvent this issue \code{GaussPy} can be trainend in
``two-steps''. One for narrow components, and one for broad
components. The result then is two independent values \(\alpha_1\)
and \(\alpha_2\) each giving information about the scales of
different features in the target function.


\section{An alternative approach}
\label{method:an-alternative-approach}
There is another alternative for calculating derivatives of
noise-ridden data, namely convolving the function with a low-pass
filter kernel, e.g., a Gaussian filter. Although the size of the
filter can be optimized by using a training routine, in a similar
fashion as we did for the \(\alpha\) scales, this technique is much
more agressive and could lead to losses of important features in the
signal. Indeed, the total variation scheme that \code{GaussPy} uses could
be thought of as the first order approximation in a perturbative
expansion of a Gaussian filter.

Notwhistanding this caveat \code{GaussPy} implements also a Gaussian
filter as an option for taking the numerical derivatives. In total,
there are three selectable \code{modes} within the package for
calculating \(f(x) + n(x)\)
\begin{itemize}
\item {} 
\code{GaussianDecomposer.set('mode','python')}: This will execute
\code{GaussPy} with a \code{Python} implementation of the total variation
algorithm. The code is clean to read, easy to understand and modify,
but it may perform slow for large datasets.

\item {} 
\code{GaussianDecomposer.set('mode','C')}: This chooses a \code{C}
implementation of the TV algorithm when calculating the
derivative. It is less time-consuming that the \code{Python} version
but comes at the price of intelligibility of some parts of the
code.

Both \code{Python} and \code{C} modes yield the same results and,
therefore, are interchangable. Our suggestion is to use \code{Python}
if you are planning to delve into the details of the code, and \code{C}
if you are after efficiency in large dataset.

\item {} 
\code{GaussianDecomposer.set('mode','conv')}: When this mode is set,
the function is Gaussian-filtered prior to calculating the numerical
derivative. In this case, the constant \(\alpha\) is taken to be
the size of the kernel
\phantomsection\label{method:equation-kernel}\begin{gather}
\begin{split}\tilde{f}(x) = (f \star K_\alpha)(x) \quad\mbox{with}\quad
     K_\alpha(x) = \frac{1}{\sqrt{2\pi \alpha^2}}{\rm e}^{-x^2/2\alpha^2}.\end{split}\label{method-kernel}
\end{gather}
Once this mode is selected the training for choosing the optimal
size of the filter proceeds in the same way we have discussed in the
previous sections, i.e., nothing else has to be changed.

\end{itemize}



\renewcommand{\indexname}{Index}
\printindex
\end{document}
